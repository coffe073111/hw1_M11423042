{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45afc9bb-0840-4093-8168-f122142a8ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building ID3 Decision Tree (custom) ===\n",
      "Train Accuracy: 0.8944893505854873\n",
      "Test  Accuracy: 0.8065249447038585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.84      0.92      0.88     12430\n",
      "        >50K       0.63      0.45      0.52      3846\n",
      "\n",
      "    accuracy                           0.81     16276\n",
      "   macro avg       0.73      0.68      0.70     16276\n",
      "weighted avg       0.79      0.81      0.79     16276\n",
      "\n",
      "\n",
      "=== Building C45 Decision Tree (custom) ===\n",
      "Train Accuracy: 0.833082337031687\n",
      "Test  Accuracy: 0.8309166871467191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.82      0.99      0.90     12430\n",
      "        >50K       0.91      0.31      0.47      3846\n",
      "\n",
      "    accuracy                           0.83     16276\n",
      "   macro avg       0.87      0.65      0.68     16276\n",
      "weighted avg       0.85      0.83      0.80     16276\n",
      "\n",
      "\n",
      "=== CART (sklearn, gini) ===\n",
      "Train Accuracy: 0.8628023480960137\n",
      "Test  Accuracy: 0.8551855492750061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.88      0.94      0.91     12430\n",
      "        >50K       0.75      0.59      0.66      3846\n",
      "\n",
      "    accuracy                           0.86     16276\n",
      "   macro avg       0.81      0.76      0.78     16276\n",
      "weighted avg       0.85      0.86      0.85     16276\n",
      "\n",
      "已輸出 Tree_CART.png（Graphviz）\n",
      "已輸出 Tree_Entropy.png（Graphviz）\n",
      "\n",
      "已輸出：DecisionTree_AllModels_Predictions.xlsx\n",
      "\n",
      "ID3 Confusion Matrix (rows=true, cols=pred):\n",
      "[[11391  1039]\n",
      " [ 2110  1736]]\n",
      "\n",
      "C4.5 Confusion Matrix (rows=true, cols=pred):\n",
      "[[12317   113]\n",
      " [ 2639  1207]]\n",
      "\n",
      "CART Confusion Matrix (rows=true, cols=pred):\n",
      "[[11667   763]\n",
      " [ 1594  2252]]\n",
      "\n",
      "完成。樹圖已輸出：Tree_CART.png、Tree_Entropy.png\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 決策樹：手刻 ID3 / C4.5 + CART (sklearn)\n",
    "# - Numeric features => 二分閾值\n",
    "# - Categorical features => 等值多路切\n",
    "# - 節點眾數 fallback\n",
    "# - Graphviz 選用，無則用 Matplotlib\n",
    "# ===============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# ---------------------------\n",
    "# 參數\n",
    "# ---------------------------\n",
    "TRAIN_PATH = \"adult_data_no_duplicates.csv\"\n",
    "TEST_PATH  = \"adult_test_no_duplicates.csv\"\n",
    "TRAIN_ID3_PATH = \"adult_data_inputation.csv\"\n",
    "\n",
    "MAX_DEPTH = 10\n",
    "MIN_SAMPLES_SPLIT = 20\n",
    "MIN_GAIN = 1e-4          # 最小資訊增益/增益率/基尼減少\n",
    "MAX_LEAF_NODES = 64\n",
    "\n",
    "# ---------------------------\n",
    "# 工具：欄名標準化\n",
    "# ---------------------------\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.strip().str.lower().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "    )\n",
    "    alias = {\"income\": \"class\", \"class.\": \"class\", \"class \": \"class\"}\n",
    "    df.rename(columns={k: v for k, v in alias.items() if k in df.columns}, inplace=True)\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# 工具：清理目標欄（只保留 <=50K / >50K）\n",
    "# ---------------------------\n",
    "def clean_target_col(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    s = df[\"class\"].astype(str).str.strip()\n",
    "    s = s.str.replace(r\"\\.$\", \"\", regex=True).str.replace(\" \", \"\", regex=False).str.upper()\n",
    "\n",
    "    s = s.replace({\n",
    "        \"<=50K.\": \"<=50K\", \">50K.\": \">50K\",\n",
    "        \"<=50K?\": \"<=50K\", \">50K?\": \">50K\",\n",
    "        \"<=50K,\": \"<=50K\", \">50K,\": \">50K\",\n",
    "        \"<=50K \": \"<=50K\", \">50K \": \">50K\"\n",
    "    }, regex=False)\n",
    "\n",
    "    s.loc[~s.isin({\"<=50K\", \">50K\"}) & s.str.contains(\"<=\", na=False)] = \"<=50K\"\n",
    "    s.loc[~s.isin({\"<=50K\", \">50K\"}) & s.str.contains(\">\",  na=False)] = \">50K\"\n",
    "\n",
    "    out = df.copy()\n",
    "    out[\"class\"] = s\n",
    "    out = out[out[\"class\"].isin({\"<=50K\", \">50K\"})].copy()\n",
    "    return out\n",
    "\n",
    "# ---------------------------\n",
    "# 讀檔 + 標準化 + 目標清理\n",
    "# ---------------------------\n",
    "train_df = pd.read_csv(TRAIN_PATH, skipinitialspace=True)\n",
    "test_df  = pd.read_csv(TEST_PATH,  skipinitialspace=True)\n",
    "train_id3_df = pd.read_csv(TRAIN_ID3_PATH, skipinitialspace=True)\n",
    "train_df = standardize_columns(train_df)\n",
    "test_df  = standardize_columns(test_df)\n",
    "train_id3_df = standardize_columns(train_id3_df)\n",
    "\n",
    "# 若測試檔沒有 header，改用訓練集欄名補上\n",
    "if \"class\" not in test_df.columns:\n",
    "    test_df = pd.read_csv(TEST_PATH, header=None, names=train_df.columns, skipinitialspace=True)\n",
    "    test_df = standardize_columns(test_df)\n",
    "\n",
    "train_df = clean_target_col(train_df)\n",
    "test_df  = clean_target_col(test_df)\n",
    "train_id3_df = clean_target_col(train_id3_df)\n",
    "\n",
    "# ---------------------------\n",
    "# X / y 切分與一致編碼\n",
    "# ---------------------------\n",
    "X_train = train_df.drop(columns=[\"class\"])\n",
    "y_train = train_df[\"class\"]\n",
    "X_test  = test_df.drop(columns=[\"class\"])\n",
    "y_test  = test_df[\"class\"]\n",
    "X_train_id3 = train_id3_df.drop(columns=[\"class\"])\n",
    "y_train_id3 = train_id3_df[\"class\"]\n",
    "\n",
    "# 記住「類別欄位」索引（手刻樹要用）\n",
    "cat_cols = X_train.select_dtypes(include=\"object\").columns.tolist()\n",
    "cat_idx = [X_train.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "# 類別欄位用同一個 OrdinalEncoder\n",
    "enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "X_train_enc = X_train.copy()\n",
    "X_test_enc  = X_test.copy()\n",
    "X_train_id3_enc  = X_train_id3.copy()\n",
    "if cat_cols:\n",
    "    X_train_enc[cat_cols] = enc.fit_transform(X_train[cat_cols].astype(str))\n",
    "    X_test_enc[cat_cols]  = enc.transform(X_test[cat_cols].astype(str))\n",
    "    X_train_id3_enc[cat_cols] = enc.fit_transform(X_train_id3_enc[cat_cols].astype(str))\n",
    "\n",
    "# 轉成 numpy\n",
    "X_train_np = X_train_enc.to_numpy(dtype=float)\n",
    "X_test_np  = X_test_enc.to_numpy(dtype=float)\n",
    "X_train_id3_np = X_train_id3_enc.to_numpy(dtype=float)\n",
    "\n",
    "# 目標欄位用同一個 LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc  = le.transform(y_test)\n",
    "y_train_id3_enc = le.fit_transform(y_train_id3)\n",
    "CLASS_NAMES = list(le.classes_)         # ['<=50K', '>50K']\n",
    "feature_names = list(X_train_enc.columns)\n",
    "\n",
    "# ===============================================================\n",
    "# Impurity & Gains\n",
    "# ===============================================================\n",
    "def entropy(y):\n",
    "    if len(y) == 0:\n",
    "        return 0.0\n",
    "    counts = np.bincount(y)\n",
    "    p = counts[counts > 0] / len(y)\n",
    "    return -np.sum(p * np.log2(p))\n",
    "\n",
    "def gini_impurity(y):\n",
    "    if len(y) == 0:\n",
    "        return 0.0\n",
    "    counts = np.bincount(y)\n",
    "    p = counts[counts > 0] / len(y)\n",
    "    return 1.0 - np.sum(p**2)\n",
    "\n",
    "def info_gain(parent_y, parts):\n",
    "    \"\"\"parts: list of child y arrays\"\"\"\n",
    "    parent_H = entropy(parent_y)\n",
    "    n = len(parent_y)\n",
    "    weighted = sum((len(pi)/n) * entropy(pi) for pi in parts)\n",
    "    return parent_H - weighted\n",
    "\n",
    "def split_info(parts, n_total):\n",
    "    \"\"\"for C4.5 gain ratio\"\"\"\n",
    "    result = 0.0\n",
    "    for p in parts:\n",
    "        w = len(p) / n_total\n",
    "        if w > 0:\n",
    "            result -= w * math.log2(w)\n",
    "    return result\n",
    "\n",
    "def gini_gain(parent_y, parts):\n",
    "    parent_G = gini_impurity(parent_y)\n",
    "    n = len(parent_y)\n",
    "    weighted = sum((len(pi)/n) * gini_impurity(pi) for pi in parts)\n",
    "    return parent_G - weighted\n",
    "\n",
    "# ===============================================================\n",
    "# 尋找最佳切分（支援數值/類別）\n",
    "# ===============================================================\n",
    "def best_split(X, y, cat_idx_set, criterion='id3'):\n",
    "    n_samples, n_features = X.shape\n",
    "    best = {\n",
    "        \"feature\": None,\n",
    "        \"threshold\": None,   # 只有數值特徵用\n",
    "        \"gain\": -1.0,\n",
    "        \"is_categorical\": False\n",
    "    }\n",
    "\n",
    "    for f in range(n_features):\n",
    "        col = X[:, f]\n",
    "        if f in cat_idx_set:\n",
    "            # 類別：等值多路切\n",
    "            values = np.unique(col)\n",
    "            parts = [y[col == v] for v in values]\n",
    "            if criterion == 'id3':\n",
    "                gain = info_gain(y, parts)\n",
    "            elif criterion in ('c45'):\n",
    "                ig = info_gain(y, parts)\n",
    "                si = split_info(parts, len(y))\n",
    "                gain = (ig / si) if si > 0 else 0.0\n",
    "            else:\n",
    "                # 其他度量可再擴充\n",
    "                gain = gini_gain(y, parts)\n",
    "\n",
    "            if gain > best[\"gain\"]:\n",
    "                best.update({\n",
    "                    \"feature\": f,\n",
    "                    \"threshold\": None,\n",
    "                    \"gain\": float(gain),\n",
    "                    \"is_categorical\": True\n",
    "                })\n",
    "        else:\n",
    "            # 數值：嘗試所有候選閾值（相鄰唯一值中點）\n",
    "            uniq = np.unique(col)\n",
    "            if len(uniq) <= 1:\n",
    "                continue\n",
    "            thresholds = (uniq[:-1] + uniq[1:]) / 2.0\n",
    "            # 向量化效率可再優化；這裡求穩定易讀\n",
    "            for thr in thresholds:\n",
    "                left_mask = col <= thr\n",
    "                right_mask = ~left_mask\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "                parts = [y_left, y_right]\n",
    "                if criterion == 'id3':\n",
    "                    gain = info_gain(y, parts)\n",
    "                elif criterion in ('c45'):\n",
    "                    ig = info_gain(y, parts)\n",
    "                    si = split_info(parts, len(y))\n",
    "                    gain = (ig / si) if si > 0 else 0.0\n",
    "                   \n",
    "                else:\n",
    "                    gain = gini_gain(y, parts)\n",
    "\n",
    "                if gain > best[\"gain\"]:\n",
    "                    best.update({\n",
    "                        \"feature\": f,\n",
    "                        \"threshold\": float(thr),\n",
    "                        \"gain\": float(gain),\n",
    "                        \"is_categorical\": False\n",
    "                    })\n",
    "    return best\n",
    "\n",
    "# ===============================================================\n",
    "# 建樹（遞迴）\n",
    "# ===============================================================\n",
    "def build_tree(X, y, feature_names, cat_idx_set,\n",
    "               criterion='id3', depth=0,\n",
    "               max_depth=MAX_DEPTH,\n",
    "               min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "               min_gain=MIN_GAIN):\n",
    "    node = {\n",
    "        \"leaf\": False,\n",
    "        \"majority_class\": int(Counter(y).most_common(1)[0][0])\n",
    "    }\n",
    "\n",
    "    # 停分條件\n",
    "    if len(np.unique(y)) == 1:\n",
    "        node.update({\"leaf\": True, \"class\": int(y[0])})\n",
    "        return node\n",
    "    if depth >= max_depth or len(y) < min_samples_split:\n",
    "        node.update({\"leaf\": True, \"class\": node[\"majority_class\"]})\n",
    "        return node\n",
    "\n",
    "    # 尋找最佳切分\n",
    "    split = best_split(X, y, cat_idx_set, criterion)\n",
    "    if split[\"feature\"] is None or split[\"gain\"] < min_gain:\n",
    "        node.update({\"leaf\": True, \"class\": node[\"majority_class\"]})\n",
    "        return node\n",
    "\n",
    "    f = split[\"feature\"]\n",
    "    node.update({\n",
    "        \"feature\": feature_names[f],\n",
    "        \"feature_index\": f,\n",
    "        \"is_categorical\": split[\"is_categorical\"],\n",
    "        \"threshold\": split[\"threshold\"],\n",
    "        \"children\": {}\n",
    "    })\n",
    "\n",
    "    if split[\"is_categorical\"]:\n",
    "        col = X[:, f]\n",
    "        for v in np.unique(col):\n",
    "            mask = (col == v)\n",
    "            child = build_tree(\n",
    "                X[mask], y[mask],\n",
    "                feature_names, cat_idx_set,\n",
    "                criterion, depth+1, max_depth, min_samples_split, min_gain\n",
    "            )\n",
    "            node[\"children\"][v] = child\n",
    "    else:\n",
    "        col = X[:, f]\n",
    "        thr = split[\"threshold\"]\n",
    "        left_mask = col <= thr\n",
    "        right_mask = ~left_mask\n",
    "        node[\"children\"][\"le\"] = build_tree(\n",
    "            X[left_mask], y[left_mask],\n",
    "            feature_names, cat_idx_set,\n",
    "            criterion, depth+1, max_depth, min_samples_split, min_gain\n",
    "        )\n",
    "        node[\"children\"][\"gt\"] = build_tree(\n",
    "            X[right_mask], y[right_mask],\n",
    "            feature_names, cat_idx_set,\n",
    "            criterion, depth+1, max_depth, min_samples_split, min_gain\n",
    "        )\n",
    "    return node\n",
    "\n",
    "# ===============================================================\n",
    "# 預測\n",
    "# ===============================================================\n",
    "def predict_one(tree, x_row):\n",
    "    if tree.get(\"leaf\", False):\n",
    "        return tree.get(\"class\", tree[\"majority_class\"])\n",
    "    fidx = tree[\"feature_index\"]\n",
    "    if tree[\"is_categorical\"]:\n",
    "        v = x_row[fidx]\n",
    "        child = tree[\"children\"].get(v)\n",
    "        if child is None:\n",
    "            return tree[\"majority_class\"]\n",
    "        return predict_one(child, x_row)\n",
    "    else:\n",
    "        thr = tree[\"threshold\"]\n",
    "        branch = \"le\" if x_row[fidx] <= thr else \"gt\"\n",
    "        child = tree[\"children\"].get(branch)\n",
    "        if child is None:\n",
    "            return tree[\"majority_class\"]\n",
    "        return predict_one(child, x_row)\n",
    "\n",
    "def predict_tree(tree, X):\n",
    "    return np.array([predict_one(tree, row) for row in X])\n",
    "\n",
    "# ===============================================================\n",
    "# 圖像輸出（Graphviz 如可用，否則 Matplotlib）\n",
    "# ===============================================================\n",
    "def save_tree_png(clf, name, feature_names, class_names, max_depth=None):\n",
    "    try:\n",
    "        import graphviz\n",
    "        from sklearn.tree import export_graphviz\n",
    "        dot = export_graphviz(\n",
    "            clf, out_file=None, feature_names=feature_names,\n",
    "            class_names=class_names, filled=False, rounded=True,\n",
    "            max_depth=max_depth\n",
    "        )\n",
    "        graphviz.Source(dot).render(name, format='png', cleanup=True)\n",
    "        print(f\"已輸出 {name}.png（Graphviz）\")\n",
    "    except Exception as e:\n",
    "        from sklearn.tree import plot_tree\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        plot_tree(clf, feature_names=feature_names, class_names=class_names,\n",
    "                  filled=False, rounded=True, max_depth=max_depth)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{name}.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"已輸出 {name}.png（Matplotlib；{e}）\")\n",
    "\n",
    "# ===============================================================\n",
    "# 訓練與評估：ID3\n",
    "# ===============================================================\n",
    "def train_and_report_id3(criterion_name):\n",
    "    print(f\"\\n=== Building {criterion_name.upper()} Decision Tree (custom) ===\")\n",
    "    tree = build_tree(X_train_id3_np, y_train_id3_enc, feature_names,\n",
    "                      set(cat_idx),\n",
    "                      criterion=criterion_name,\n",
    "                      max_depth=MAX_DEPTH,\n",
    "                      min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "                      min_gain=MIN_GAIN)\n",
    "    y_tr_pred = predict_tree(tree, X_train_id3_np)\n",
    "    y_te_pred = predict_tree(tree, X_test_np)\n",
    "\n",
    "    print(\"Train Accuracy:\", accuracy_score(y_train_enc, y_tr_pred))\n",
    "    print(\"Test  Accuracy:\",  accuracy_score(y_test_enc,  y_te_pred))\n",
    "    print(classification_report(y_test_enc, y_te_pred, target_names=CLASS_NAMES, digits=2))\n",
    "    return tree, y_te_pred\n",
    "\n",
    "tree_id3, y_test_pred_id3 = train_and_report_id3('id3')\n",
    "\n",
    "# ===============================================================\n",
    "# 訓練與評估：C4.5\n",
    "# ===============================================================\n",
    "def train_and_report(criterion_name):\n",
    "    print(f\"\\n=== Building {criterion_name.upper()} Decision Tree (custom) ===\")\n",
    "    tree = build_tree(X_train_np, y_train_enc, feature_names,\n",
    "                      set(cat_idx),\n",
    "                      criterion=criterion_name,\n",
    "                      max_depth=MAX_DEPTH,\n",
    "                      min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "                      min_gain=MIN_GAIN)\n",
    "    y_tr_pred = predict_tree(tree, X_train_np)\n",
    "    y_te_pred = predict_tree(tree, X_test_np)\n",
    "\n",
    "    print(\"Train Accuracy:\", accuracy_score(y_train_enc, y_tr_pred))\n",
    "    print(\"Test  Accuracy:\",  accuracy_score(y_test_enc,  y_te_pred))\n",
    "    print(classification_report(y_test_enc, y_te_pred, target_names=CLASS_NAMES, digits=2))\n",
    "    return tree, y_te_pred\n",
    "\n",
    "tree_c45, y_test_pred_c45 = train_and_report('c45')\n",
    "\n",
    "# ===============================================================\n",
    "# sklearn 基準樹：CART(gini) + Entropy（近似可視化）\n",
    "# ===============================================================\n",
    "clf_cart = DecisionTreeClassifier(criterion='gini', max_depth=MAX_DEPTH,\n",
    "                                  max_leaf_nodes=MAX_LEAF_NODES,\n",
    "                                  min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "                                  random_state=42)\n",
    "clf_cart.fit(X_train_np, y_train_enc)\n",
    "y_train_pred_cart = clf_cart.predict(X_train_np)\n",
    "y_test_pred_cart  = clf_cart.predict(X_test_np)\n",
    "print(\"\\n=== CART (sklearn, gini) ===\")\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train_enc, y_train_pred_cart))\n",
    "print(\"Test  Accuracy:\",  accuracy_score(y_test_enc,  y_test_pred_cart))\n",
    "print(classification_report(y_test_enc, y_test_pred_cart, target_names=CLASS_NAMES, digits=2))\n",
    "save_tree_png(clf_cart, \"Tree_CART\", feature_names, CLASS_NAMES, max_depth=MAX_DEPTH)\n",
    "\n",
    "# 只為了提供近似視覺化（與手刻樹不同步）\n",
    "clf_entropy = DecisionTreeClassifier(criterion='entropy', max_depth=MAX_DEPTH,\n",
    "                                     max_leaf_nodes=MAX_LEAF_NODES,\n",
    "                                     min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "                                     random_state=42)\n",
    "clf_entropy.fit(X_train_np, y_train_enc)\n",
    "save_tree_png(clf_entropy, \"Tree_Entropy\", feature_names, CLASS_NAMES, max_depth=MAX_DEPTH)\n",
    "\n",
    "# ===============================================================\n",
    "# 匯出整合結果\n",
    "# ===============================================================\n",
    "output_all = pd.DataFrame({\n",
    "    \"Actual\": y_test_enc,\n",
    "    \"ID3_Pred\":  y_test_pred_id3,\n",
    "    \"C45_Pred\":  y_test_pred_c45,\n",
    "    \"CART_Pred\": y_test_pred_cart\n",
    "})\n",
    "try:\n",
    "    output_all.to_excel(\"DecisionTree_AllModels_Predictions.xlsx\", index=False)\n",
    "    print(\"\\n已輸出：DecisionTree_AllModels_Predictions.xlsx\")\n",
    "except Exception as e:\n",
    "    output_all.to_csv(\"DecisionTree_AllModels_Predictions.csv\", index=False)\n",
    "    print(f\"\\nExcel 匯出失敗（{e}），已改存 CSV：DecisionTree_AllModels_Predictions.csv\")\n",
    "\n",
    "# 額外：輸出混淆矩陣（看類別 1 不再全 0）\n",
    "def print_cm(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    print(f\"\\n{title} Confusion Matrix (rows=true, cols=pred):\\n{cm}\")\n",
    "\n",
    "print_cm(y_test_enc, y_test_pred_id3, \"ID3\")\n",
    "print_cm(y_test_enc, y_test_pred_c45, \"C4.5\")\n",
    "print_cm(y_test_enc, y_test_pred_cart, \"CART\")\n",
    "\n",
    "print(\"\\n完成。樹圖已輸出：Tree_CART.png、Tree_Entropy.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11532994-ac65-4088-aab0-50dc78827e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphviz 繪圖失敗 (Length of feature_names, 14 does not match number of features, 17)，改用 Matplotlib。\n",
      "已使用 Matplotlib 輸出 Tree_ID3.png（深度=3, 節點≤64）\n",
      "已使用 Graphviz 輸出 Tree_C45.png（深度=3, 節點≤64）\n",
      "已使用 Graphviz 輸出 Tree_CART.png（深度=3, 節點≤64）\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 統一決策樹視覺化（ID3 / C4.5 / CART）\n",
    "# 若未安裝 graphviz → 自動改用 matplotlib\n",
    "# 統一深度：3\n",
    "# 節點數 ≤ 64\n",
    "# 黑白風格 (filled=False)\n",
    "# ===============================================================\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz, plot_tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "MAX_DEPTH_VIS = 3\n",
    "MAX_LEAF_VIS  = 64\n",
    "\n",
    "# 嘗試載入 graphviz，如果沒有則 fallback\n",
    "try:\n",
    "    import graphviz\n",
    "    HAS_GRAPHVIZ = True\n",
    "except ImportError:\n",
    "    HAS_GRAPHVIZ = False\n",
    "    print(\"未偵測到 Graphviz，將自動改用 Matplotlib 輸出 PNG。\")\n",
    "\n",
    "def export_tree_safely(X, y, feature_names, class_names, criterion, filename):\n",
    "    \"\"\"\n",
    "    自動選擇 Graphviz 或 Matplotlib 方式繪製決策樹\n",
    "    \"\"\"\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion='entropy' if criterion in ('id3', 'c45') else 'gini',\n",
    "        max_depth=MAX_DEPTH_VIS,\n",
    "        max_leaf_nodes=MAX_LEAF_VIS,\n",
    "        min_samples_split=MIN_SAMPLES_SPLIT,\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    if HAS_GRAPHVIZ:\n",
    "        try:\n",
    "            dot = export_graphviz(\n",
    "                clf,\n",
    "                out_file=None,\n",
    "                feature_names=feature_names,\n",
    "                class_names=class_names,\n",
    "                filled=False,      # 黑白風格\n",
    "                rounded=True,\n",
    "                max_depth=MAX_DEPTH_VIS\n",
    "            )\n",
    "            graphviz.Source(dot).render(filename, format='png', cleanup=True)\n",
    "            print(f\"已使用 Graphviz 輸出 {filename}.png（深度={MAX_DEPTH_VIS}, 節點≤{MAX_LEAF_VIS}）\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"Graphviz 繪圖失敗 ({e})，改用 Matplotlib。\")\n",
    "\n",
    "    # --- Fallback: Matplotlib ---\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plot_tree(\n",
    "        clf,\n",
    "        feature_names=feature_names,\n",
    "        class_names=class_names,\n",
    "        filled=False,   # 黑白\n",
    "        rounded=True,\n",
    "        max_depth=MAX_DEPTH_VIS\n",
    "    )\n",
    "    plt.title(f\"{filename} (depth={MAX_DEPTH_VIS}, leaf≤{MAX_LEAF_VIS})\", fontsize=14)\n",
    "    plt.savefig(f\"{filename}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"已使用 Matplotlib 輸出 {filename}.png（深度={MAX_DEPTH_VIS}, 節點≤{MAX_LEAF_VIS}）\")\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# ID3、C4.5、CART模型輸出\n",
    "# ===============================================================\n",
    "export_tree_safely(X_train_id3_np, y_train_id3_enc, feature_names, CLASS_NAMES, 'id3', \"Tree_ID3\")\n",
    "export_tree_safely(X_train_np, y_train_enc, feature_names, CLASS_NAMES, 'c45', \"Tree_C45\")\n",
    "export_tree_safely(X_train_np, y_train_enc, feature_names, CLASS_NAMES, 'cart', \"Tree_CART\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bcd544-fb02-46f6-ba98-d71c534db68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
